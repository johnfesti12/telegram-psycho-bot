import os
import logging
import PyPDF2
import docx
from database import SubscriptionManager

logger = logging.getLogger(__name__)

class PsychologyKnowledgeBase:
    def __init__(self, subscription_manager):
        self.sub_manager = subscription_manager
        self.knowledge_base = {}
        self.load_books()
    
    def load_books(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–Ω–∏–≥ –∏–∑ –ø–∞–ø–∫–∏ books"""
        books_dir = "./books"
        if not os.path.exists(books_dir):
            os.makedirs(books_dir)
            print("üìÅ –°–æ–∑–¥–∞–Ω–∞ –ø–∞–ø–∫–∞ 'books'. –î–æ–±–∞–≤—å—Ç–µ —Ç—É–¥–∞ –∫–Ω–∏–≥–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ PDF, TXT –∏–ª–∏ DOCX!")
            return
        
        supported_files = []
        for filename in os.listdir(books_dir):
            if filename.lower().endswith(('.pdf', '.txt', '.docx')):
                supported_files.append(filename)
        
        if not supported_files:
            print("üìö –í –ø–∞–ø–∫–µ 'books' –Ω–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤ (PDF, TXT, DOCX)")
            return
        
        print(f"üìñ –ù–∞–π–¥–µ–Ω–æ –∫–Ω–∏–≥: {len(supported_files)}")
        
        for filename in supported_files:
            file_path = os.path.join(books_dir, filename)
            try:
                if filename.lower().endswith('.pdf'):
                    text = self.read_pdf(file_path)
                elif filename.lower().endswith('.docx'):
                    text = self.read_docx(file_path)
                else:  # txt
                    with open(file_path, 'r', encoding='utf-8') as f:
                        text = f.read()
                
                if text:
                    self.knowledge_base[filename] = {
                        'content': text,
                        'type': filename.split('.')[-1].upper()
                    }
                    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞: {filename} ({len(text)} —Å–∏–º–≤–æ–ª–æ–≤)")
                else:
                    print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å: {filename}")
                    
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {filename}: {e}")
    
    def read_pdf(self, file_path):
        """–ß—Ç–µ–Ω–∏–µ PDF —Ñ–∞–π–ª–æ–≤ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        text = ""
        try:
            with open(file_path, 'rb') as file:
                reader = PyPDF2.PdfReader(file)
                
                for page_num in range(len(reader.pages)):
                    page = reader.pages[page_num]
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"
                
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è PDF {file_path}: {e}")
            # –ü–æ–ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥
            try:
                import pdfplumber
                with pdfplumber.open(file_path) as pdf:
                    for page in pdf.pages:
                        page_text = page.extract_text()
                        if page_text:
                            text += page_text + "\n"
            except:
                pass
        
        return text
    
    def read_docx(self, file_path):
        """–ß—Ç–µ–Ω–∏–µ DOCX —Ñ–∞–π–ª–æ–≤"""
        text = ""
        try:
            doc = docx.Document(file_path)
            for paragraph in doc.paragraphs:
                if paragraph.text.strip():
                    text += paragraph.text + "\n"
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è DOCX {file_path}: {e}")
        
        return text
    
    def search_in_books(self, query, max_results=3):
        """–ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –∫–Ω–∏–≥–∞—Ö"""
        if not self.knowledge_base:
            return "üìö –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –ø—É—Å—Ç–∞. –î–æ–±–∞–≤—å—Ç–µ –∫–Ω–∏–≥–∏ –≤ –ø–∞–ø–∫—É 'books'."
        
        query_lower = query.lower()
        relevant_results = []
        
        for book_name, book_data in self.knowledge_base.items():
            content = book_data['content']
            content_lower = content.lower()
            
            # –ò—â–µ–º –≤—Ö–æ–∂–¥–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞
            if query_lower in content_lower:
                # –ù–∞—Ö–æ–¥–∏–º –ø–æ–∑–∏—Ü–∏—é –ø–µ—Ä–≤–æ–≥–æ –≤—Ö–æ–∂–¥–µ–Ω–∏—è
                index = content_lower.find(query_lower)

                # –ë–µ—Ä–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞
                start = max(0, index - 150)
                end = min(len(content), index + 350)
                
                excerpt = content[start:end]
                
                # –û—á–∏—â–∞–µ–º –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç
                excerpt = self.clean_text(excerpt)
                
                relevant_results.append({
                    'book': book_name,
                    'excerpt': excerpt,
                    'position': index
                })
            
            if len(relevant_results) >= max_results:
                break
        
        if not relevant_results:
            return "üîç –í –±–∏–±–ª–∏–æ—Ç–µ–∫–µ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É."
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        result_text = "üìö <b>–ù–∞–π–¥–µ–Ω–æ –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ:</b>\n\n"
        for i, result in enumerate(relevant_results, 1):
            result_text += f"<b>{i}. {result['book']}</b>\n"
            result_text += f"<i>{result['excerpt']}...</i>\n\n"
        
        return result_text
    
    def clean_text(self, text):
        """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤ –∏ –ø–µ—Ä–µ–Ω–æ—Å–æ–≤"""
        # –ó–∞–º–µ–Ω—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã –∏ –ø—Ä–æ–±–µ–ª—ã
        import re
        text = re.sub(r'\n+', '\n', text)
        text = re.sub(r' +', ' ', text)
        return text.strip()
    
    def get_library_info(self):
        """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ"""
        if not self.knowledge_base:
            return "üìö –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –ø—É—Å—Ç–∞"
        
        total_books = len(self.knowledge_base)
        book_types = {}
        
        for book_data in self.knowledge_base.values():
            book_type = book_data['type']
            book_types[book_type] = book_types.get(book_type, 0) + 1
        
        type_info = ", ".join([f"{count} {typ}" for typ, count in book_types.items()])
        
        return f"üìö –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞: {total_books} –∫–Ω–∏–≥ ({type_info})"
    
    def get_context_for_ai(self, query, max_excerpts=18):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –∫–Ω–∏–≥ –¥–ª—è AI"""
        if not self.knowledge_base:
            return ""
        
        query_lower = query.lower()
        query_words = [word for word in query_lower.split() if len(word) > 3]  # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞
        relevant_excerpts = []
        
        for book_name, book_data in self.knowledge_base.items():
            content = book_data['content']
            content_lower = content.lower()
            
            # –°—á–∏—Ç–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
            relevance_score = sum(1 for word in query_words if word in content_lower)
            
            if relevance_score > 0:
                # –ù–∞—Ö–æ–¥–∏–º –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –æ—Ç—Ä—ã–≤–æ–∫
                paragraphs = content.split('\n\n')  # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
                
                for paragraph in paragraphs:
                    if any(word in paragraph.lower() for word in query_words):
                        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –æ—Ç—Ä—ã–≤–∫–∞
                        if len(paragraph) > 500:
                            paragraph = paragraph[:500] + "..."
                        
                        relevant_excerpts.append({
                            'book': book_name,
                            'text': paragraph.strip(),
                            'score': relevance_score
                        })
                        break  # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –æ—Ç—Ä—ã–≤–æ–∫ –∏–∑ –∫–∞–∂–¥–æ–π –∫–Ω–∏–≥–∏
            
            if len(relevant_excerpts) >= max_excerpts:
                break
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        relevant_excerpts.sort(key=lambda x: x['score'], reverse=True)
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–ª—è AI
        if relevant_excerpts:
            context_text = "–†–ï–õ–ï–í–ê–ù–¢–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø –ò–ó –ü–°–ò–•–û–õ–û–ì–ò–ß–ï–°–ö–û–ô –õ–ò–¢–ï–†–ê–¢–£–†–´:\n\n"
            for excerpt in relevant_excerpts:
                context_text += f"üìñ –ò–∑ –∫–Ω–∏–≥–∏ '{excerpt['book']}':\n{excerpt['text']}\n\n"
            
            return context_text.strip()
        
        return ""